{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generation\n",
    "\n",
    "Images are all taken from the [HiRISE Satellite](https://hirise.lpl.arizona.edu/). These images can be programatically downloaded using the script below. When run in full, the script can take over a day to run depending on your connection speed. It will download approximately 50,000 images (64 GB).\n",
    "\n",
    "The images are processed into 512x512 patches and saved individually. Using the full dataset will generate 644,000 images (64 GB). The image patches are then resized and saved at sizes 8x8, 16x16, 32x32, 64x64, 128x128 and 256x256. This is not necessary, but speeds up training of a progressive GAN. The sizes of the downscaled files range from 1.9 GB for the 8x8 dataset to 18 GB for the 256x256 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'F:/Mars/full_size/' # path to save destination\n",
    "\n",
    "url = 'https://hirise-pds.lpl.arizona.edu/PDS/EXTRAS/RDR/ESP/'\n",
    "r = requests.get(url)\n",
    "html = BeautifulSoup(r.content, \"html.parser\")\n",
    "a = html.findAll('a') # anchor elements are all folders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# script to download all images\n",
    "# change iteration in first for loop to a count based method if you don't want to download the entire thing\n",
    "for o_folder in a:\n",
    "    folder = o_folder.text\n",
    "\n",
    "    if 'ORB' in folder:\n",
    "        print(folder)\n",
    "        folder_url = url + folder\n",
    "\n",
    "        r2 = requests.get(folder_url)\n",
    "        html2 = BeautifulSoup(r2.content, \"html.parser\")\n",
    "        a2 = html2.findAll('a')\n",
    "\n",
    "        for e_folder in a2:\n",
    "            sub_folder = e_folder.text\n",
    "            if 'ESP' in sub_folder:\n",
    "                print(sub_folder)\n",
    "                sub_folder_url = folder_url + sub_folder\n",
    "\n",
    "                r3 = requests.get(sub_folder_url)\n",
    "                html3 = BeautifulSoup(r3.content, \"html.parser\")\n",
    "                a3 = html3.findAll('a')\n",
    "\n",
    "                try:\n",
    "                    file_lr = [i.text for i in a3 if '_RGB.NOMAP.browse.jpg' in i.text][0]\n",
    "                    !curl -sS {sub_folder_url+file_lr} > {image_path+file_lr}\n",
    "\n",
    "                except:\n",
    "                    print('\\tfailed to find filename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('G:/Mars/')\n",
    "large_fnames = os.listdir(path/'full_size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f, fname in enumerate(large_fnames):\n",
    "    \n",
    "    if f%1000 == 0:\n",
    "        print(f)\n",
    "    \n",
    "    im_id = fname.split('_RGB')[0]\n",
    "    \n",
    "    im = open_image(path/'full_size'/fname)\n",
    "    im = im.rotate(180) # rotation helps avoid single color channel artifacts at the top of many images\n",
    "    data = im.data\n",
    "    if data.shape[2] >= 512:\n",
    "        patches = data.unfold(1, 512, 512).unfold(2, 512, 512)\n",
    "\n",
    "        for i in range(patches.shape[1]):\n",
    "            for j in range(patches.shape[2]):\n",
    "                patch_fname = im_id + '_' + str(i) + '_' + str(j) + '.jpg'\n",
    "                pil_im = PIL.Image.fromarray(image2np(patches[:, i, j, :, :]*255).astype('uint8'))\n",
    "                pil_im.save(path/'image_patches'/patch_fname, quality=95)\n",
    "    else:\n",
    "        print('thin image') # some images are less than 512 on the thinnest side - these are discarded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_fnames = os.listdir(path/'image_patches')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to resize patches\n",
    "for f, filename in enumerate(patch_fnames):\n",
    "    if f%1000 == 0:\n",
    "        print(f)\n",
    "    \n",
    "    ims = [open_image(path/'image_patches'/filename) for i in range(6)]\n",
    "    \n",
    "    im1 = ims[0].resize((3,256,256))\n",
    "    im2 = ims[1].resize((3,128,128))    \n",
    "    im3 = ims[2].resize((3,64,64))\n",
    "    im4 = ims[3].resize((3,32,32))\n",
    "    im5 = ims[4].resize((3,16,16))\n",
    "    im6 = ims[5].resize((3,8,8))\n",
    "    \n",
    "    PIL.Image.fromarray(image2np(im1.data*255).astype(np.uint8)).save(path/'patches_256'/filename, quality=95)\n",
    "    PIL.Image.fromarray(image2np(im2.data*255).astype(np.uint8)).save(path/'patches_128'/filename, quality=95)\n",
    "    PIL.Image.fromarray(image2np(im3.data*255).astype(np.uint8)).save(path/'patches_64'/filename, quality=95)\n",
    "    PIL.Image.fromarray(image2np(im4.data*255).astype(np.uint8)).save(path/'patches_32'/filename, quality=95)\n",
    "    PIL.Image.fromarray(image2np(im5.data*255).astype(np.uint8)).save(path/'patches_16'/filename, quality=95)\n",
    "    PIL.Image.fromarray(image2np(im6.data*255).astype(np.uint8)).save(path/'patches_8'/filename, quality=95)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
