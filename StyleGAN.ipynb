{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mars StyleGAN\n",
    "\n",
    "The [Basic Gan](https://github.com/kheyer/MarsGAN/blob/master/Basic%20Gan.ipynb) notebook showed that a very simple generator/discriminator setup can generate fake Mars landscapes that are poor quality but still recognizable. The basic GAN suffered from several flaws. The images generated were blurry, pixilated and full of artifacts. The images were small, 64x64 pixels. Training a model of the same architecture to create larger images proved unstable. In this notebook, we use a more sophistocated generator to create higher quality images at larger sizes. We are going to use the famous [StyleGAN](https://arxiv.org/pdf/1812.04948.pdf).\n",
    "\n",
    "StyleGAN is noteworthy because it was the first GAN model to disentangle the latent factors used to generate an image. Most GAN models start with a random vector that is used to generate an image. StyleGAN does things differently. A random latent vector is first sent through a mapping network consisting of several fully connected layers. This allows the generator to learn an intermediate latent space that is best for generating images. The intermediate latent vector is then injected into the generator at different layers.\n",
    "\n",
    "![](media/stylegan.png)\n",
    "\n",
    "The key finding of StyleGAN was that adding the intermediate latent vector at different layers of the generator caused different effects on the output image. Injection at early layers of the generator influenced major details of the image, while injection at later layers influenced finer details. The result is that the StyleGAN generator can be used to blend different latent vectors.\n",
    "\n",
    "![](media/stylegan_mixing.jpg)\n",
    "\n",
    "StyleGAN is able to train with good stability to images as large as 1024x1024 by training with [progressive growing](https://arxiv.org/pdf/1710.10196.pdf). We start training on 4x4 images. After some time, we grow to 8x8, then 16x16 and so on. When we grow the model, there's a small issue. We now have a new layer that converts a tensor of activations to a 3 channel RGB image. Since this new layer is untrained, it likely produces poor quality images. To prevent this from messing up training, the new RGB layer is phased in.\n",
    "\n",
    "![](media/rgb.png)\n",
    "\n",
    "So that's a quick overview. Lets start looking at the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from fastai.vision.gan import *\n",
    "from fastai.callbacks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('G:/Mars/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(bs, size, path, num_workers, noise_size=512):\n",
    "    return (GANItemList.from_folder(path, noise_sz=noise_size)\n",
    "               .split_none()\n",
    "               .label_from_func(noop)\n",
    "               .transform(tfms=[[crop_pad(size=size, row_pct=(0,1), col_pct=(0,1))], []], size=size, tfm_y=True)\n",
    "               .databunch(bs=bs, num_workers=num_workers)\n",
    "               .normalize(stats = [torch.tensor([0.5,0.5,0.5]), torch.tensor([0.5,0.5,0.5])], do_x=False, do_y=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I resized the main dataset into individual sets for each image size\n",
    "# This has a noticeable effect on training speed\n",
    "data_4 = get_data(256, 4, path/'patches_4', 8)\n",
    "data_8 = get_data(256, 8, path/'patches_8', 8)\n",
    "data_16 = get_data(128, 16, path/'patches_16', 8)\n",
    "data_32 = get_data(128, 32, path/'patches_32', 8)\n",
    "data_64 = get_data(48, 64, path/'patches_64', 8)\n",
    "data_128 = get_data(22, 128, path/'patches_128', 8)\n",
    "data_256 = get_data(10, 256, path/'patches_256', 8)\n",
    "data_512 = get_data(4, 512, path/'image_patches', 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StyleGAN Fundamentals\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EqualLR:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "\n",
    "    def compute_weight(self, module):\n",
    "        weight = getattr(module, self.name + '_orig')\n",
    "        fan_in = weight.data.size(1) * weight.data[0][0].numel()\n",
    "\n",
    "        return weight * math.sqrt(2 / fan_in)\n",
    "\n",
    "    @staticmethod\n",
    "    def apply(module, name):\n",
    "        fn = EqualLR(name)\n",
    "\n",
    "        weight = getattr(module, name)\n",
    "        del module._parameters[name]\n",
    "        module.register_parameter(name + '_orig', nn.Parameter(weight.data))\n",
    "        module.register_forward_pre_hook(fn)\n",
    "\n",
    "        return fn\n",
    "\n",
    "    def __call__(self, module, input):\n",
    "        weight = self.compute_weight(module)\n",
    "        setattr(module, self.name, weight)\n",
    "\n",
    "\n",
    "def equal_lr(module, name='weight'):\n",
    "    EqualLR.apply(module, name)\n",
    "\n",
    "    return module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EqualConv2d(nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        conv = nn.Conv2d(*args, **kwargs)\n",
    "        conv.weight.data.normal_()\n",
    "        conv.bias.data.zero_()\n",
    "        self.conv = equal_lr(conv)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.conv(input)\n",
    "\n",
    "\n",
    "class EqualLinear(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        linear = nn.Linear(in_dim, out_dim)\n",
    "        linear.weight.data.normal_()\n",
    "        linear.bias.data.zero_()\n",
    "\n",
    "        self.linear = equal_lr(linear)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.linear(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channel,\n",
    "        out_channel,\n",
    "        kernel_size,\n",
    "        padding,\n",
    "        kernel_size2=None,\n",
    "        padding2=None,\n",
    "        pixel_norm=True,\n",
    "        spectral_norm=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        pad1 = padding\n",
    "        pad2 = padding\n",
    "        if padding2 is not None:\n",
    "            pad2 = padding2\n",
    "\n",
    "        kernel1 = kernel_size\n",
    "        kernel2 = kernel_size\n",
    "        if kernel_size2 is not None:\n",
    "            kernel2 = kernel_size2\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            EqualConv2d(in_channel, out_channel, kernel1, padding=pad1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            EqualConv2d(out_channel, out_channel, kernel2, padding=pad2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        out = self.conv(input)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PixelNorm(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, input):\n",
    "        return input / torch.sqrt(torch.mean(input ** 2, dim=1, keepdim=True) + 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaptiveInstanceNorm(nn.Module):\n",
    "    def __init__(self, in_channel, style_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.norm = nn.InstanceNorm2d(in_channel)\n",
    "        self.style = EqualLinear(style_dim, in_channel * 2)\n",
    "\n",
    "        self.style.linear.bias.data[:in_channel] = 1\n",
    "        self.style.linear.bias.data[in_channel:] = 0\n",
    "\n",
    "    def forward(self, input, style):\n",
    "        style = self.style(style).unsqueeze(2).unsqueeze(3)\n",
    "        gamma, beta = style.chunk(2, 1)\n",
    "\n",
    "        out = self.norm(input)\n",
    "        out = gamma * out + beta\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoiseInjection(nn.Module):\n",
    "    def __init__(self, channel):\n",
    "        super().__init__()\n",
    "\n",
    "        self.weight = nn.Parameter(torch.zeros(1, channel, 1, 1))\n",
    "\n",
    "    def forward(self, image, noise):\n",
    "        return image + self.weight * noise\n",
    "\n",
    "\n",
    "class ConstantInput(nn.Module):\n",
    "    def __init__(self, channel, size=4):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input = nn.Parameter(torch.randn(1, channel, size, size))\n",
    "\n",
    "    def forward(self, input):\n",
    "        batch = input.shape[0]\n",
    "        out = self.input.repeat(batch, 1, 1, 1)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StyledConvBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channel,\n",
    "        out_channel,\n",
    "        kernel_size=3,\n",
    "        padding=1,\n",
    "        style_dim=512,\n",
    "        initial=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        if initial:\n",
    "            self.conv1 = ConstantInput(in_channel)\n",
    "\n",
    "        else:\n",
    "            self.conv1 = EqualConv2d(\n",
    "                in_channel, out_channel, kernel_size, padding=padding\n",
    "            )\n",
    "\n",
    "        self.noise1 = equal_lr(NoiseInjection(out_channel))\n",
    "        self.adain1 = AdaptiveInstanceNorm(out_channel, style_dim)\n",
    "        self.lrelu1 = nn.LeakyReLU(0.2)\n",
    "\n",
    "        self.conv2 = EqualConv2d(out_channel, out_channel, kernel_size, padding=padding)\n",
    "        self.noise2 = equal_lr(NoiseInjection(out_channel))\n",
    "        self.adain2 = AdaptiveInstanceNorm(out_channel, style_dim)\n",
    "        self.lrelu2 = nn.LeakyReLU(0.2)\n",
    "\n",
    "    def forward(self, input, style, noise):\n",
    "        out = self.conv1(input)\n",
    "        out = self.noise1(out, noise)\n",
    "        out = self.adain1(out, style)\n",
    "        out = self.lrelu1(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.noise2(out, noise)\n",
    "        out = self.adain2(out, style)\n",
    "        out = self.lrelu2(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, code_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.progression = nn.ModuleList(\n",
    "            [\n",
    "                StyledConvBlock(512, 512, 3, 1, initial=True),\n",
    "                StyledConvBlock(512, 512, 3, 1),\n",
    "                StyledConvBlock(512, 512, 3, 1),\n",
    "                StyledConvBlock(512, 512, 3, 1),\n",
    "                StyledConvBlock(512, 256, 3, 1),\n",
    "                StyledConvBlock(256, 128, 3, 1),\n",
    "                StyledConvBlock(128, 64, 3, 1),\n",
    "                StyledConvBlock(64, 32, 3, 1),\n",
    "                StyledConvBlock(32, 16, 3, 1),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.to_rgb = nn.ModuleList(\n",
    "            [\n",
    "                EqualConv2d(512, 3, 1),\n",
    "                EqualConv2d(512, 3, 1),\n",
    "                EqualConv2d(512, 3, 1),\n",
    "                EqualConv2d(512, 3, 1),\n",
    "                EqualConv2d(256, 3, 1),\n",
    "                EqualConv2d(128, 3, 1),\n",
    "                EqualConv2d(64, 3, 1),\n",
    "                EqualConv2d(32, 3, 1),\n",
    "                EqualConv2d(16, 3, 1),\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "    def forward(self, style, noise, step=0, alpha=-1, mixing_range=(-1, -1)):\n",
    "        out = noise[0]\n",
    "\n",
    "        if len(style) < 2:\n",
    "            inject_index = [len(self.progression) + 1]\n",
    "\n",
    "        else:\n",
    "            inject_index = random.sample(list(range(step)), len(style) - 1)\n",
    "\n",
    "        crossover = 0\n",
    "\n",
    "        for i, (conv, to_rgb) in enumerate(zip(self.progression, self.to_rgb)):\n",
    "            if mixing_range == (-1, -1):\n",
    "                if crossover < len(inject_index) and i > inject_index[crossover]:\n",
    "                    crossover = min(crossover + 1, len(style))\n",
    "\n",
    "                style_step = style[crossover]\n",
    "\n",
    "            else:\n",
    "                if mixing_range[0] <= i <= mixing_range[1]:\n",
    "                    style_step = style[1]\n",
    "\n",
    "                else:\n",
    "                    style_step = style[0]\n",
    "\n",
    "            if i > 0 and step > 0:\n",
    "                upsample = F.interpolate(\n",
    "                    out, scale_factor=2, mode='bilinear', align_corners=False\n",
    "                )\n",
    "                # upsample = self.blur(upsample)\n",
    "                out = conv(upsample, style_step, noise[i])\n",
    "\n",
    "            else:\n",
    "                out = conv(out, style_step, noise[i])\n",
    "\n",
    "            if i == step:\n",
    "                out = to_rgb(out)\n",
    "\n",
    "                if i > 0 and alpha > 0: #0 <= alpha < 1:\n",
    "                    skip_rgb = self.to_rgb[i - 1](upsample)\n",
    "                    out = alpha * skip_rgb + (1 - alpha) * out\n",
    "\n",
    "                break\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StyledGenerator(nn.Module):\n",
    "    def __init__(self, code_dim=512, n_mlp=8):\n",
    "        super().__init__()\n",
    "\n",
    "        self.generator = Generator(code_dim)\n",
    "\n",
    "        layers = [PixelNorm()]\n",
    "        for i in range(n_mlp):\n",
    "            layers.append(EqualLinear(code_dim, code_dim))\n",
    "            layers.append(nn.LeakyReLU(0.2))\n",
    "\n",
    "        self.style = nn.Sequential(*layers)\n",
    "        \n",
    "        self.step = 0\n",
    "        self.alpha = 0\n",
    "\n",
    "    def forward(self, input, noise=None, mean_style=None, style_weight=0, mixing_range=(-1, -1), mixing=True):\n",
    "        \n",
    "        bs, ch, _, _ = input.shape\n",
    "        input = input.view(bs, ch)\n",
    "        \n",
    "        if self.step < 1:\n",
    "            mixing=False\n",
    "        \n",
    "        if mixing and random.random() < 0.9:\n",
    "            shuffle = torch.randperm(input.size(0)).to(input.device)\n",
    "            input = [input, input[shuffle]]\n",
    "        else:\n",
    "            input = [input]  \n",
    "        \n",
    "        styles = []\n",
    "\n",
    "        for i in input:\n",
    "            styles.append(self.style(i))\n",
    "\n",
    "        batch = input[0].shape[0]\n",
    "\n",
    "        if noise is None:\n",
    "            noise = []\n",
    "\n",
    "            for i in range(self.step + 1):\n",
    "                size = 4 * 2 ** i\n",
    "                noise.append(torch.randn(batch, 1, size, size, device=input[0].device))\n",
    "\n",
    "        if mean_style is not None:\n",
    "            styles_norm = []\n",
    "\n",
    "            for style in styles:\n",
    "                styles_norm.append(mean_style + style_weight * (style - mean_style))\n",
    "\n",
    "            styles = styles_norm\n",
    "\n",
    "        return self.generator(styles, noise, self.step, self.alpha, mixing_range=mixing_range)\n",
    "\n",
    "    def mean_style(self, input):\n",
    "        style = self.style(input).mean(0, keepdim=True)\n",
    "\n",
    "        return style\n",
    "        \n",
    "    def grow_model(self, step=None, alpha=None):\n",
    "        if step:\n",
    "            self.step = step\n",
    "        else:\n",
    "            self.step += 1\n",
    "            \n",
    "        if alpha is not None:\n",
    "            self.alpha = alpha\n",
    "        else:\n",
    "            self.alpha = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.progression = nn.ModuleList(\n",
    "            [\n",
    "                ConvBlock(16, 32, 3, 1),\n",
    "                ConvBlock(32, 64, 3, 1),\n",
    "                ConvBlock(64, 128, 3, 1),\n",
    "                ConvBlock(128, 256, 3, 1),\n",
    "                ConvBlock(256, 512, 3, 1),\n",
    "                ConvBlock(512, 512, 3, 1),\n",
    "                ConvBlock(512, 512, 3, 1),\n",
    "                ConvBlock(512, 512, 3, 1),\n",
    "                ConvBlock(513, 512, 3, 1, 4, 0),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.from_rgb = nn.ModuleList(\n",
    "            [\n",
    "                EqualConv2d(3, 16, 1),\n",
    "                EqualConv2d(3, 32, 1),\n",
    "                EqualConv2d(3, 64, 1),\n",
    "                EqualConv2d(3, 128, 1),\n",
    "                EqualConv2d(3, 256, 1),\n",
    "                EqualConv2d(3, 512, 1),\n",
    "                EqualConv2d(3, 512, 1),\n",
    "                EqualConv2d(3, 512, 1),\n",
    "                EqualConv2d(3, 512, 1),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # self.blur = Blur()\n",
    "\n",
    "        self.n_layer = len(self.progression)\n",
    "\n",
    "        self.linear = EqualLinear(512, 1)\n",
    "        \n",
    "        self.step = 0\n",
    "        self.alpha = 0\n",
    "\n",
    "    def forward(self, input, actual=False):\n",
    "        if actual:\n",
    "            for i in range(self.step, -1, -1):\n",
    "                index = self.n_layer - i - 1\n",
    "\n",
    "                if i == self.step:\n",
    "                    out = self.from_rgb[index](input)\n",
    "\n",
    "                if i == 0:\n",
    "                    out_std = torch.sqrt(out.var(0, unbiased=False) + 1e-8)\n",
    "                    mean_std = out_std.mean()\n",
    "                    mean_std = mean_std.expand(out.size(0), 1, 4, 4)\n",
    "                    out = torch.cat([out, mean_std], 1)\n",
    "\n",
    "                out = self.progression[index](out)\n",
    "\n",
    "                if i > 0:\n",
    "                    # out = F.avg_pool2d(out, 2)\n",
    "                    out = F.interpolate(\n",
    "                        out, scale_factor=0.5, mode='bilinear', align_corners=False\n",
    "                    )\n",
    "\n",
    "                    if i == self.step and self.alpha > 0:  #0 <= alpha < 1:\n",
    "                        # skip_rgb = F.avg_pool2d(input, 2)\n",
    "                        skip_rgb = self.from_rgb[index + 1](input)\n",
    "                        skip_rgb = F.interpolate(\n",
    "                            skip_rgb, scale_factor=0.5, mode='bilinear', align_corners=False\n",
    "                        )\n",
    "\n",
    "                        out = self.alpha * skip_rgb + (1 - self.alpha) * out\n",
    "\n",
    "            out = out.squeeze(2).squeeze(2)\n",
    "            out = self.linear(out)\n",
    "\n",
    "            return (out, input)\n",
    "        else:\n",
    "            return (None, input)\n",
    "    \n",
    "    def grow_model(self, step=None, alpha=None):\n",
    "        if step:\n",
    "            self.step = step\n",
    "        else:\n",
    "            self.step += 1\n",
    "            \n",
    "        if alpha is not None:\n",
    "            self.alpha = alpha\n",
    "        else:\n",
    "            self.alpha = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StyleCriticLoss_WGANGP(nn.Module):\n",
    "    \n",
    "    def forward(self, real, fake, gradient):\n",
    "        loss = fake.mean() - real.mean() + 0.001 * real.pow(2).mean() + gradient\n",
    "        return loss        \n",
    "        \n",
    "class StyleGenLoss_WGANGP(nn.Module):\n",
    "    \n",
    "    def forward(self, fake_pred, *args):\n",
    "        return -fake_pred.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StyleCriticLoss_R1(nn.Module):\n",
    "    \n",
    "    def forward(self, fake, gradient_predict):\n",
    "        real_predict = F.softplus(-gradient_predict[0]).mean()\n",
    "        \n",
    "        grad_real = torch.autograd.grad(outputs=gradient_predict[0].sum(), inputs=gradient_predict[1], create_graph=True)[0]\n",
    "        #grad_penalty = grad_real.pow(2).sum()\n",
    "        grad_penalty = grad_real.view(grad_real.size(0), -1).norm(2, dim=1).pow(2).mean()\n",
    "        grad_penalty = 10 / 2 * grad_penalty\n",
    "        \n",
    "        fake_predict = F.softplus(fake).mean()\n",
    "        \n",
    "        loss = real_predict + fake_predict + grad_penalty\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "class StyleGenLoss_R1(nn.Module):\n",
    "    \n",
    "    def forward(self, fake_pred, *args):\n",
    "        return F.softplus(-fake_pred).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANLossGradient(GANModule):\n",
    "    \"Wrapper around `loss_funcC` (for the critic) and `loss_funcG` (for the generator).\"\n",
    "    def __init__(self, loss_funcG:Callable, loss_funcC:Callable, gan_model:GANModule, grad_scale=10):\n",
    "        super().__init__()\n",
    "        self.loss_funcG,self.loss_funcC,self.gan_model = loss_funcG,loss_funcC,gan_model\n",
    "        self.grad_scale = grad_scale\n",
    "\n",
    "    def generator(self, output, target):\n",
    "        \"Evaluate the `output` with the critic then uses `self.loss_funcG` to combine it with `target`.\"\n",
    "        fake_pred = self.gan_model.critic(output, actual=True)[0]\n",
    "        return self.loss_funcG(fake_pred, target, output)\n",
    "\n",
    "    def critic(self, real_pred, input):\n",
    "        \"Create some `fake_pred` with the generator from `input` and compare them to `real_pred` in `self.loss_funcD`.\"\n",
    "        fake = self.gan_model.generator(input.requires_grad_(False)).requires_grad_(True)\n",
    "        fake_pred = self.gan_model.critic(fake, actual=True)\n",
    "        \n",
    "        real_pred[1].requires_grad = True\n",
    "        gradient_predict = self.gan_model.critic(real_pred[1], actual=True)\n",
    "        \n",
    "        return self.loss_funcC(fake_pred[0], gradient_predict)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlphaDecay(LearnerCallback):\n",
    "    \n",
    "    def __init__(self, learn, end_batch):\n",
    "        super().__init__(learn)\n",
    "        self.end_batch = end_batch\n",
    "        self.initial_alpha = self.learn.model.generator.alpha\n",
    "        \n",
    "    def on_batch_begin(self, iteration, **kwargs):\n",
    "        if self.learn.model.generator.alpha > 0:\n",
    "            self.learn.model.generator.alpha = self.initial_alpha - iteration / self.end_batch\n",
    "            self.learn.model.critic.alpha = self.initial_alpha - iteration / self.end_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StyleGANLearner(Learner):\n",
    "    \"A `Learner` suitable for GANs.\"\n",
    "    def __init__(self, data:DataBunch, generator:nn.Module, critic:nn.Module, gen_loss_func:LossFunction,\n",
    "                 crit_loss_func:LossFunction, switcher:Callback=None, gen_first:bool=False, switch_eval:bool=True,\n",
    "                 show_img:bool=True, clip:float=None, alpha_batch=10, **learn_kwargs):\n",
    "        gan = GANModule(generator, critic)\n",
    "        loss_func = GANLossGradient(gen_loss_func, crit_loss_func, gan)\n",
    "        switcher = ifnone(switcher, partial(FixedGANSwitcher, n_crit=5, n_gen=1))\n",
    "        super().__init__(data, gan, loss_func=loss_func, callback_fns=[switcher], **learn_kwargs)\n",
    "        trainer = GANTrainer(self, clip=clip, switch_eval=switch_eval, show_img=show_img)\n",
    "        self.gan_trainer = trainer\n",
    "        self.callbacks.append(trainer)\n",
    "        self.callback_fns.append(partial(AlphaDecay, end_batch=alpha_batch))\n",
    "\n",
    "    @classmethod\n",
    "    def from_learners(cls, learn_gen:Learner, learn_crit:Learner, switcher:Callback=None,\n",
    "                      weights_gen:Tuple[float,float]=None, **learn_kwargs):\n",
    "        \"Create a GAN from `learn_gen` and `learn_crit`.\"\n",
    "        losses = gan_loss_from_func(learn_gen.loss_func, learn_crit.loss_func, weights_gen=weights_gen)\n",
    "        return cls(learn_gen.data, learn_gen.model, learn_crit.model, *losses, switcher=switcher, **learn_kwargs)\n",
    "\n",
    "    @classmethod\n",
    "    def stylegan_wgan(cls, data:DataBunch, generator:nn.Module, critic:nn.Module, \n",
    "             switcher:Callback=None, clip:float=0.01, **learn_kwargs):\n",
    "        \"Create a WGAN from `data`, `generator` and `critic`.\"\n",
    "        return cls(data, generator, critic, StyleGenLoss_WGANGP(), \n",
    "                       StyleCriticLoss_WGANGP(), switcher=switcher, clip=clip, **learn_kwargs)\n",
    "    \n",
    "    @classmethod\n",
    "    def stylegan_r1(cls, data:DataBunch, generator:nn.Module, critic:nn.Module, \n",
    "             switcher:Callback=None, clip:float=0.01, **learn_kwargs):\n",
    "        \"Create a WGAN from `data`, `generator` and `critic`.\"\n",
    "        return cls(data, generator, critic, StyleGenLoss_R1(), \n",
    "                       StyleCriticLoss_R1(), switcher=switcher, clip=clip, **learn_kwargs)\n",
    "\n",
    "    def grow_model(self, data, step=None, alpha=None, alpha_batch=None):\n",
    "        self.model.generator.grow_model(step=step, alpha=alpha)\n",
    "        self.model.critic.grow_model(step=step, alpha=alpha)\n",
    "        self.data = data\n",
    "        \n",
    "        if alpha_batch is not None:\n",
    "            self.callback_fns[-1] = partial(AlphaDecay, end_batch=alpha_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
